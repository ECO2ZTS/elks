{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# PCA算法简介\n",
    "\n",
    "PCA主成分分析通过线性变换将原始数据变换为一组各维度线性无关的表示，可用于提取数据的主要特征分量，常用于高维数据的降维。\n",
    "降维当然意味着信息的丢失，不过鉴于实际数据本身常常存在的相关性，可以想办法在降维的同时将信息的损失尽量降低。\n",
    "\n",
    "## 问题\n",
    "\n",
    "- 我们到底删除哪一维损失的信息才最小？亦或根本不是单纯删除几列，而是通过某些变换将原始数据变为更少的列但又使得丢失的信息最小？\n",
    "- 到底如何度量丢失信息的多少？\n",
    "- 如何根据原始数据决定具体的降维操作步骤？\n",
    "\n",
    "## 基本思路\n",
    "\n",
    "PCA通过严格的数学推理来处理了这些问题。这里不重视严格推理，简要掌握过程。\n",
    "\n",
    "### 降维与基变换\n",
    "\n",
    "根据线性代数的知识可以知道，选择不同的基可以对同样一组数据给出不同的表示（向量向不同基方向投影结果就是坐标），而且如果基的数量少于向量本身的维数，则可以达到降维的效果。\n",
    "\n",
    "而矩阵相乘就是线性变化，可以作用于一组基上，使之变为另一种基，也就是说选择矩阵变换的形式对应了选择某种基。\n",
    "\n",
    "但是如何选择基才是最优的。或者说，如果有一组N维向量，现在要将其降到K维（K小于N），那么我们应该如何选择K个基才能最大程度保留原有的信息？\n",
    "\n",
    "直观上讲是希望投影后的投影值尽可能分散。因为如果不相同的点投影后重叠了，那就是一种严重的信息丢失。举个例子：\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-1. -1.  0.  2.  0.]\n",
      " [-2.  0.  0.  1.  1.]]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "a=np.array([[1,1,2,4,2],[1,3,3,4,4]])\n",
    "a=np.array([(a[0]-np.mean(a[0])),(a[1]-np.mean(a[1]))])\n",
    "print(a)\n",
    "fig=plt.figure()\n",
    "ax=fig.add_axes([0,0,1,1])\n",
    "ax.scatter(a[0],a[1])\n",
    "ax.set_xlim([-5,4])\n",
    "ax.set_ylim([-5,4])\n",
    "\n",
    "ax.spines['right'].set_color('none')\n",
    "ax.spines['top'].set_color('none')\n",
    "ax.xaxis.set_ticks_position('bottom')\n",
    "ax.spines['bottom'].set_position(('data',0))\n",
    "ax.yaxis.set_ticks_position('left')\n",
    "ax.spines['left'].set_position(('data',0))\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### 方差\n",
    "\n",
    "如上图所示，如果我们必须使用一维来表示这些数据，又希望尽量保留原始的信息，你要如何选择？\n",
    "\n",
    "这个问题实际上是要在二维平面中选择一个方向，将所有数据都投影到这个方向所在直线上，用投影值表示原始记录。这是一个实际的二维降到一维的问题。\n",
    "\n",
    "那么如何选择这个方向（或者说基）才能尽量保留最多的原始信息呢？一种直观的看法是：希望投影后的投影值尽可能分散。\n",
    "\n",
    "希望投影后投影值尽可能分散，而这种分散程度，可以用数学上的方差来表述。\n",
    "\n",
    "一个字段的方差可以看做是每个元素与字段均值的差的平方和的均值。\n",
    "\n",
    "于是上面的问题被形式化表述为：寻找一个**一维基**，使得所有数据变换为这个基上的坐标表示后，方差值最大。\n",
    "\n",
    "### 协方差\n",
    "\n",
    "但是对于较高维的情况，如何考虑？\n",
    "\n",
    "考虑三维降到二维问题。与之前相同，首先我们希望找到一个方向使得投影后方差最大，这样就完成了第一个方向的选择，继而我们选择第二个投影方向。\n",
    "\n",
    "如果我们还是单纯只选择方差最大的方向，很明显，这个方向与第一个方向应该是“几乎重合在一起”，显然这样的维度是没有用的，因此，应该有其他约束条件。\n",
    "因为相关性意味着两个字段不是完全独立，必然存在重复表示的信息。\n",
    "\n",
    "数学上可以用两个字段的协方差表示其相关性。为了让协方差为0，我们选择第二个基时只能在与第一个基正交的方向上选择。因此最终选择的两个方向一定是正交的。\n",
    "\n",
    "至此，我们得到了降维问题的优化目标：\n",
    "将一组N维向量降为K维（K大于0，小于N），其目标是选择K个单位（模为1）正交基，使得原始数据变换到这组基上后，各字段两两间协方差为0，而字段的方差则尽可能大（在正交的约束下，取最大的K个方差）。\n",
    "\n",
    "### 协方差矩阵\n",
    "\n",
    "数学上，各字段两两间协方差和字段的方差两者可以被**统一到一个矩阵**。\n",
    "\n",
    "对于任一m个n维数据（归一化过的）组成的n*m矩阵X：\n",
    "\n",
    "$C=\\frac{1}{m} XX^T$\n",
    "\n",
    "为一个对称矩阵，其对角线各元素为各个字段的方差，矩阵是对角阵，第i行第j列元素表示i和j两个字段的协方差。\n",
    "\n",
    "### 协方差矩阵对角化\n",
    "\n",
    "现在可以发现要达到优化目的，等价于将协方差矩阵对角化：即除对角线外的其它元素化为0，并且在对角线上将元素按大小从上到下排列，这样我们就实现了各字段两两间协方差为0，而字段的方差则尽可能大，前面最大的几行就是要选的维数。\n",
    "\n",
    "令P是一组基按行组成的矩阵，设Y=PX，则Y为X对P做基变换后的数据。设Y的协方差矩阵为D，推导D与C的关系：\n",
    "\n",
    "$$D=\\frac{1}{m} YY^T=\\frac{1}{m} (PX)(PX)^T=\\frac{1}{m} PXX^TP^T=P(\\frac{1}{m}XX^T)P^T=PCP^T$$\n",
    "\n",
    "所以现在就很清楚了，就是要找一个P，使得PCP^T=D矩阵其除对角线外的其它元素为0，对角线上元素从大到小排列。\n",
    "\n",
    "### PCA\n",
    "\n",
    "上述问题在数学上早就被解决了，不是什么大问题。因为C是一个实对称矩阵，寻找C的特征值和特征向量是很常见的问题。\n",
    "\n",
    "对C的n个特征向量组成的矩阵E有：\n",
    "\n",
    "$E^TCE=\\Lambda$\n",
    "\n",
    "$\\Lambda$是对角阵，各元素为各特征向量对应的特征值。\n",
    "\n",
    "因此，$P=E^T$，即P是协方差矩阵的特征向量单位化后按行排列出的矩阵，其中每一行都是C的一个特征向量。\n",
    "设P按照$\\Lambda$中特征值的从大到小，将特征向量从上到下排列，则用P的前K行组成的矩阵乘以原始数据矩阵X，就得到了我们需要的降维后的数据矩阵Y。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1.2 0.8]\n",
      " [0.8 1.2]]\n",
      "[2.  0.4]\n",
      "[[ 0.70710678  0.70710678]\n",
      " [-0.70710678  0.70710678]]\n",
      "[[ 2.00000000e+00  0.00000000e+00]\n",
      " [-1.38777878e-16  4.00000000e-01]]\n",
      "[-2.12132034 -0.70710678  0.          2.12132034  0.70710678]\n"
     ]
    }
   ],
   "source": [
    "C=1/5*np.dot(a,a.T)\n",
    "print(C)\n",
    "# 求特征值\n",
    "eigenvalue,featurevector=np.linalg.eig(C)\n",
    "print(eigenvalue)\n",
    "P=featurevector.T\n",
    "print(P)\n",
    "# 验证C的对角化\n",
    "D=P.dot(C).dot(P.T)\n",
    "print(D)\n",
    "# 用P的第一行乘以数据矩阵，就得到了降维后的表示\n",
    "Y=P[0].dot(a)\n",
    "print(Y)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "metadata": {
     "collapsed": false
    },
    "source": []
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
