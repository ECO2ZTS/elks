{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 决策树\n",
    "\n",
    "水文水资源种常常用到各类分类或回归的及其学习算法，本文简单整理下决策树及其相关算法，包括集成学习树，随机森林等。\n",
    "\n",
    "首先看看使用决策树作为预测模型来预测样本的类标。这种决策树也称作分类树（如果是用作回归，就是回归树）。\n",
    "\n",
    "## CART决策树算法\n",
    "\n",
    "在数据挖掘中，决策树主要有两种类型:\n",
    "\n",
    "- 分类树 的输出是样本的类标。 \n",
    "- 回归树 的输出是一个实数 (例如房子的价格，病人呆在医院的时间等)。\n",
    "\n",
    "通常决策树主要有三种实现，分别是ID3算法，CART算法和C4.5算法。 本文以CART为例记录。\n",
    "\n",
    "本节主要参考：\n",
    "\n",
    "1. [维基百科](https://zh.wikipedia.org/wiki/%E5%86%B3%E7%AD%96%E6%A0%91%E5%AD%A6%E4%B9%A0)\n",
    "2. [数据挖掘十大经典算法--CART: 分类与回归树](https://wizardforcel.gitbooks.io/dm-algo-top10/content/cart.html)\n",
    "3. [CART算法](https://zhuanlan.zhihu.com/p/32003259)\n",
    "4. [机器学习之分类与回归树(CART)](https://zhuanlan.zhihu.com/p/36108972)\n",
    "5. [分类回归树CART(上)](https://www.cnblogs.com/zhangchaoyang/articles/2709922.html)\n",
    "6. [决策树](https://github.com/Vay-keen/Machine-learning-learning-notes/blob/master/%E5%91%A8%E5%BF%97%E5%8D%8E%E3%80%8AMachine%20Learning%E3%80%8B%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0(5)--%E5%86%B3%E7%AD%96%E6%A0%91.md)\n",
    "7. [机器学习笔记十二：分类与回归树CART](https://blog.csdn.net/xierhacker/article/details/64439601)\n",
    "\n",
    "### 基本概念\n",
    "\n",
    "决策树是基于树结构来进行决策的，网上看到一个例子十分有趣。母亲想要给自己的女娃介绍一个男朋友，于是有了下面的对话：\n",
    "\n",
    "  女儿：多大年纪了？\n",
    "  母亲：26。\n",
    "  女儿：长的帅不帅？\n",
    "  母亲：挺帅的。\n",
    "  女儿：收入高不？\n",
    "  母亲：不算很高，中等情况。\n",
    "  女儿：是公务员不？\n",
    "  母亲：是，在税务局上班呢。\n",
    "  女儿：那好，我去见见。\n",
    "\n",
    "该过程就是一个典型的决策树（在树的结构里， 叶子节点给出类标而内部节点代表某个属性），即相当于**通过年龄、长相、收入和是否公务员**将男童鞋分为**两个类别**：见和不见。\n",
    "\n",
    "![example](68747470733a2f2f692e6c6f6c692e6e65742f323031382f31302f31372f356263373238656338346137372e706e67.png)\n",
    "\n",
    "决策过程的每次判定都是对某一属性的“测试”。那么也可知决策树包含：一个根节点、若干个内部节点和若干个叶子节点，易知：\n",
    "\n",
    "* **每个非叶节点表示一个特征属性**测试。\n",
    "* 每个分支代表这个特征属性在某个值域上的输出。\n",
    "* **每个叶子节点存放一个类别**。\n",
    "* 每个节点包含的样本集合通过属性测试被划分到子节点中，根节点包含样本全集。\n",
    "\n",
    "结合上图很容易理解，简单概括下，就是根节点是所有样本，然后沿着分支，会根据分支上的某个属性在某个值域上的输出将样本进行分类，然后依次进行到最后的叶节点，就完成了分类过程。\n",
    "\n",
    "术语分类和回归树Classification And Regression Tree (CART) 是决策树的一种实现。CART算法是一种二分递归分割技术，把当前样本划分为两个子样本，使得生成的每个非叶子结点都有两个分支，因此CART算法生成的决策树是结构简洁的二叉树。由于CART算法构成的是一个二叉树，它在每一步的决策时只能是“是”或者“否”，即非叶子节点的特征取值为True和False，左分支取值为True，右分支取值为False，即使一个feature有多个取值，也是把数据分为两部分。CART可以处理连续型变量和离散型变量，利用训练数据递归的划分特征空间进行建树，用验证数据进行剪枝。\n",
    "\n",
    "- 如果待预测分类是离散型数据，则CART生成分类决策树。\n",
    "- 如果待预测分类是连续性数据，则CART生成回归决策树。\n",
    "\n",
    "在CART算法中主要分为两个步骤\n",
    "\n",
    "1. 将样本递归划分进行建树过程\n",
    "2. 用验证数据进行剪枝\n",
    "\n",
    "### 构造\n",
    "\n",
    "注意构造决策树的输入有两个集合，一个是训练集，一个是属性集。结合前面的例子，就是一个女生已经相亲过有很多男生，这些男生就是训练集，而属性集是女生自己定的条件。构造决策树的动机可以理解成现在有一个新的男生，他想根据这个女生之前对男生的分类来判断自己有没有可能在她的yes中。那现在这个男生就需要构造一个决策树来分析了。决策树的构造是一个递归的过程，如图所示：\n",
    "![train](68747470733a2f2f692e6c6f6c692e6e65742f323031382f31302f31372f356263373238656363323766652e706e67.png)\n",
    "\n",
    "结合例子，就是之前全部男生都被女生排除了，那就是全部都是no；如果女生根本就没有选，只是不想相亲，那么就没有属性，全部no，那就只能将所有哥们直接标记成no了；接着是比较正常的情况，对这个女生分析，要分析哪个是最优划分属性，收入还是外貌等等，然后对这个属性的每个取值，生成一个分支，选出各个男生里面符合这个条件的，如果没有符合这个条件的，比如年薪百万的没有，那这些哥们被no的原因就是这个了，全部分到no就完事了；如果还真有，那这个就是yes了，那可能有其他原因被no，就对这几个百万哥继续分，用除了年薪这个属性之外的属性去分，递归重复类似的过程，一直到所有哥们都被分完。\n",
    "\n",
    "那么可以想象，为什么是先考虑收入，而不是才华呢？你怎么就知道那个妹子不是喜欢有才华的呢？也就是说构造决策树的依据是什么呢？而这就是决策树学习的关键，关键在于**如何选择划分属性**，**不同的划分属性得出不同的分支结构**，从而影响整颗决策树的性能。属性划分的目标是让各个划分出来的**子节点尽可能地“纯”，即属于同一类别**。\n",
    "\n",
    "接下来就以CART算法为例稍微叙述下。CART算法构建决策树时在每一步选择一个最好的属性来分裂。CART决策树使用**“基尼指数”（Gini index）**来选择划分属性，基尼指数反映的是从样本集D中随机抽取两个样本，其类别标记不一致的概率，因此Gini(D)越小越好。\n",
    "$$Gini(D)=\\sum _{k=1}^{|y|}\\sum _{k'\\neq k}p_k p_{k'}=1-\\sum _{k=1}^{|y|}p_k^2$$\n",
    "使用某个属性a划分后的基尼指数为：\n",
    "$$Gini\\_index(D,a)=\\sum _{v=1}^{V}\\frac{|D^v|}{|D|}Gini(D^v)$$\n",
    "选择基尼指数最小的划分属性。\n",
    "\n",
    "### 剪枝处理\n",
    "\n",
    "从决策树的构造流程中我们可以直观地看出：不管怎么样的训练集，决策树总是能很好地将各个类别分离开来，这时就会遇到之前提到过的问题：过拟合（overfitting），即太依赖于训练样本。剪枝（pruning）则是决策树算法对付过拟合的主要手段。这里暂不赘述了。\n",
    "\n",
    "### 连续值与缺失值处理\n",
    "\n",
    "对于连续值的属性，每个取值作为一个分支显然不可行，因此需要进行离散化处理，常用的方法为二分法，基本思想为：给定样本集D与连续属性α，二分法试图找到一个划分点t将样本集D在属性α上分为≤t与＞t。\n",
    "\n",
    "* 首先将α的所有取值按升序排列，所有相邻属性的均值作为候选划分点（n-1个，n为α所有的取值数目）。\n",
    "* 计算每一个划分点划分集合D（即划分为两个分支）后的信息增益。\n",
    "* 选择最大信息增益的划分点作为最优划分点。\n",
    "\n",
    "$$Gain(D,a)=max_{t\\in T_a}\\ Gain(D,a,t)=max_{t\\in T_a}\\ Ent(D)-\\sum _{\\lambda \\in {-,+}}\\frac{|D_t^v|}{|D|}Ent(D_t^{\\lambda})$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1])"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import tree\n",
    "X = [[0, 0], [1, 1]]\n",
    "Y = [0, 1]\n",
    "clf = tree.DecisionTreeClassifier()\n",
    "clf = clf.fit(X, Y)\n",
    "clf.predict([[2., 2.]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "前面虽然提到了CART可以用到回归，不过没细说，这里最后补充点关于回归树的内容。\n",
    "\n",
    "设有数据集D，X和Y分别代表输入和输出变量，其中Y是连续变量（回归模型），包含m个样本的数据集D可以表示为$D=\\{(x^{(1)},y^{(1)}),(x^{(2)},y^{(2)}),\\cdots,(x^{(m)},y^{(m)})\\}$\n",
    "\n",
    "一个回归树的本质代表着**一个被划分的输入空间**和**这些划分单元上面各自的输出值**。\n",
    "\n",
    "比如，一个回归树能够将一个输出空间划分为K个部分$R_1,R_2,\\cdots,R_K$，并且在每个部分$R_K$上面有一个固定的输出值$c_k$，那么回归树模型可以表示为：\n",
    "$$f(x)=\\sum_{k=1}^K c_kI(x\\in R_k)$$\n",
    "也就是说，只要模型正确的建立起来，只要知道输入向量属于哪个部分，就可以得到它的值了，上式中I()指指示函数。\n",
    "\n",
    "比如一组数据：\n",
    "\n",
    "1 12 31\n",
    "\n",
    "2 13 32\n",
    "\n",
    "3 14 33\n",
    "\n",
    "4 15 34\n",
    "\n",
    "5 16 35\n",
    "\n",
    "每一列是一个特征，比如以第一列，特征0，来分类，大于2的称为一类，这就划分了。\n",
    "\n",
    "然后以特征1分类，比如大于14的一类。\n",
    "\n",
    "所以CART回归和分类类似，训练的时候需要知道什么是切分变量和切分点，切分就是指分割输入空间的意思。切分比哪里就是切分特征，即在某个特征上面进行选择，切分点就是一个值，这个值一个集合分成两边，切分特征和切分点共同决定一个集合应该以怎么样的方式来切分。CART回归非常重要的就是寻找最优切分特征和最优切分点。优化函数的目标如下式所示：\n",
    "$$\\sum_{x^{(i)}\\in R_k}(y^{(i)}-f(x^{(i)}))^2$$\n",
    "以上例来分析，遍历所有输入变量来找最优切分特征j和最优切分点s，即：\n",
    "$$min_{j,s}[min_{c_1} \\sum_{x^{(i)}\\in R_1(j,s)}(y^{(i)}-c_1)^2 + min_{c_2} \\sum_{x^{(i)}\\in R_2(j,s)}(y^{(i)}-c_2)^2]$$\n",
    "通常认为一个区域上面的结果为该区域对应所有输出的均值，即\n",
    "$$\\widehat{c_m}=mean(y|x\\in R_m)$$\n",
    "也就是说，对于上面找最优切分点的时候，$c_1,c_2$可以替换成该区域上面的所有输出的均值。\n",
    "\n",
    "找到最优切分(j,s)之后，切分就能将集合切分成总损失最小的两个部分。对于切分出来的区域再重复递归这样的划分过程，直到满足条件为止，那么就生成了一棵回归树。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bagging\n",
    "\n",
    "针对决策树算法，可以通过模型融合大大提高其精确度。一个决策树是弱的，整合多个弱模型能够构造一个强的模型，三个臭皮匠顶个诸葛亮。本节就简单记录下集成学习决策树相关的内容。\n",
    "\n",
    "主要参考：\n",
    "\n",
    "1. [【机器学习】决策树及Bagging, Random Forest和Boosting模型融合](https://blog.csdn.net/AmourDeMai/article/details/51457406)\n",
    "2. [Vay-keen/Machine-learning-learning-notes/周志华《Machine Learning》学习笔记(10)--集成学习.md](https://github.com/Vay-keen/Machine-learning-learning-notes/blob/master/%E5%91%A8%E5%BF%97%E5%8D%8E%E3%80%8AMachine%20Learning%E3%80%8B%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0(10)--%E9%9B%86%E6%88%90%E5%AD%A6%E4%B9%A0.md)\n",
    "3. [Bagging算法](https://zh.wikipedia.org/wiki/Bagging%E7%AE%97%E6%B3%95)\n",
    "\n",
    "集成学习（ensemble learning）指的是将多个学习器进行有效地结合，组建一个“学习器委员会”，其中每个学习器担任委员会成员并行使投票表决权，使得委员会最后的决定更能更优，即其泛化性能要能优于其中任何一个学习器。\n",
    "\n",
    "集成学习的基本结构为：先产生一组个体学习器，再使用某种策略将它们结合在一起。\n",
    "\n",
    "![集成学习](68747470733a2f2f692e6c6f6c692e6e65742f323031382f31302f31382f356263383464306331353638332e706e67.png)\n",
    "\n",
    "若个体学习器都属于同一类别，例如都是决策树或都是神经网络，则称该集成为同质的（homogeneous）;若个体学习器包含多种类型的学习算法，例如既有决策树又有神经网络，则称该集成为异质的（heterogenous）。同质集成：个体学习器称为“基学习器”（base learner），对应的学习算法为“基学习算法”（base learning algorithm）。 异质集成：个体学习器称为“组件学习器”（component learner）或直称为“个体学习器”。\n",
    "\n",
    "虽说团结力量大但也有木桶短板理论调皮捣蛋，那如何做到呢？这就引出了集成学习的两个重要概念：准确性和多样性（diversity）。准确性指的是个体学习器不能太差，要有一定的准确度；多样性则是个体学习器之间的输出要具有差异性。**产生“好而不同”的个体学习器**正是集成学习研究的核心。\n",
    "\n",
    "比如考虑二分类的简单情形，假设基分类器(输出为$h_i (x)$)之间相互独立（能提供较高的差异度），且错误率相等为 ε，则可以将集成器的预测H(x)看做一个伯努利实验，易知当所有基分类器中不足一半预测正确的情况下，集成器预测错误，所以集成器的错误率可以计算为：\n",
    "$$H(x)=sign(\\sum _{T}^{i=1}h_i(x))$$\n",
    "$$P(H(x)\\neq f(x))=\\sum _{k=0}^{\\lfloor T/2\\rfloor}C_T^k (1-\\epsilon)^k\\epsilon ^{T-k}\\le exp(-\\frac1 2 T(1-2\\epsilon)^2)$$\n",
    "\n",
    "此时，集成器错误率随着基分类器的个数的增加呈指数下降，但前提是基分类器之间相互独立，在实际情形中显然是不可能的，假设训练有A和B两个分类器，对于某个测试样本，显然满足：P（A=1 | B=1）> P（A=1），因为A和B为了解决相同的问题而训练，因此在预测新样本时存在着很大的联系。因此，个体学习器的“准确性”和“差异性”本身就是一对矛盾的变量，准确性高意味着牺牲多样性，所以产生“好而不同”的个体学习器正是集成学习研究的核心。现阶段有三种主流的集成学习方法：Boosting、Bagging以及随机森林（Random Forest），接下来根据实际应用中遇到的情况逐渐补充记录。\n",
    "\n",
    "本节先关注Bagging算法。Bagging与后面记录的Random Forest的基本思（tao）想（lu）都是通过“**自助采样**”的方法来增加多样性。\n",
    "\n",
    "Bagging算法全称为bootstrap aggregating，引导聚集算法，Bagging是一种并行式的集成学习方法，即**基学习器的训练**之间没有前后顺序可以**同时进行**，Bagging使用“有放回”采样的方式选取训练集，对于包含m个样本的训练集，进行m次有放回的**随机采样**操作，从而得到m个样本的采样集，这样训练集中有接近36.8%的样本没有被采到（见下式）。按照相同的方式重复进行，我们就可以采集到T个包含m个样本的数据集，从而训练出T个基学习器，**最终对这T个基学习器的输出进行结合**，比如通过取平均值、取多数票等方法，即可得到Bagging的结果。。\n",
    "$$\\lim_{m\\to\\infty}(1-\\frac 1 m)^m = \\frac 1 e \\simeq 0.368$$\n",
    "Bagging算法的流程如下所示：\n",
    "\n",
    "![](68747470733a2f2f692e6c6f6c692e6e65742f323031382f31302f31382f356263383464306430653736312e706e67.png)\n",
    "\n",
    "Bagging主要通过样本的扰动来增加基学习器之间的多样性，因此Bagging的基学习器应为那些对训练集十分敏感的不稳定学习算法，例如：神经网络与决策树等。从偏差-方差分解来看，Bagging算法主要关注于**降低方差，即通过多次重复训练提高稳定性**。不同于AdaBoost的是，Bagging可以十分简单地移植到多分类、回归等问题。总的说起来则是：AdaBoost关注于降低偏差，而Bagging关注于降低方差。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest简介\n",
    "\n",
    "随机森林是水文统计分析中常用的一种分类或回归算法，因此有必要了解其基本原理，以顺利读懂相关文献。\n",
    "\n",
    "本文主要参考：\n",
    "\n",
    "1. [说说随机森林](https://zhuanlan.zhihu.com/p/22097796)\n",
    "2. [周志华《Machine Learning》学习笔记(10)--集成学习](https://github.com/Vay-keen/Machine-learning-learning-notes/blob/master/%E5%91%A8%E5%BF%97%E5%8D%8E%E3%80%8AMachine%20Learning%E3%80%8B%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0(10)--%E9%9B%86%E6%88%90%E5%AD%A6%E4%B9%A0.md)\n",
    "3. [理解随机森林：基于Python的实现和解释](https://www.jiqizhixin.com/articles/2018-12-22-3)\n",
    "4. [Random Forest Tutorial.ipynb](https://github.com/TryEnlight/Machine-Learning-Projects/blob/master/Random%20Forest%20Tutorial.ipynb)\n",
    "5. [随机森林回归 sklearn.ensemble.RandomForestRegressor](https://blog.csdn.net/GitzLiu/article/details/81952712)\n",
    "6. [从零实现回归随机森林](https://zhuanlan.zhihu.com/p/52052903)\n",
    "7. [利用随机森林对特征重要性进行评估](https://blog.csdn.net/zjuPeco/article/details/77371645)\n",
    "\n",
    "### 基本概念\n",
    "\n",
    "随机森林顾名思义，是用随机的方式建立一个森林，森林里面有很多的决策树组成，随机森林的每一棵决策树（关于决策树相关的基础也可参考本目录下的CART一文）之间是没有关联的。\n",
    "\n",
    "决策树实际上是将空间用超平面进行划分的一种方法，每次分割的时候，都将当前的空间一分为二（图来自参考1）。\n",
    "\n",
    "![DT](fbed6853d3c557892dc735960eb7f56e_hd.png)\n",
    "\n",
    "![sample_space](bd9d3fe215ad812ddd3ca7133251b38a_hd.png)\n",
    "\n",
    "决策树代码示例如下："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision tree has 9 nodes with maximum depth 3.\n",
      "Model Accuracy: 1.0\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAkkAAAImCAYAAABHIh67AAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjEsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy8QZhcZAAAgAElEQVR4nO3deVjVdf7//weyCISGgQurWGoZSmnq5J6mpiNTmpo1llBdWX4nzSwzdewzppYLUzN1iSVZozbR2GJumTZWLqTlrlOOWLmQLAqKyCbr7w9/nOnIi03O4RzwfrsurovX6/16vXm+372Dh+/tuGRmZpYKAAAAVho5ugAAAABnREgCAAAwICQBAAAYEJIAAAAMCEkAAAAGhCQAAAADQhIAAICBm6MLAHBtmjBhguLj46363Nzc1KRJE/n6+qpDhw664447NHLkSIWFhdn852/fvl07duxQp06dFBkZafP1A6j/OJMEwKHc3d3VokULtWjRQs2aNVNeXp6OHz+uzz//XHPmzFHnzp0VFRWl9PR0m/7cHTt2aMGCBdqwYYNN1wug4SAkAXCo7t27KzExUYmJiTp27JhSU1N14sQJffzxx7r//vvl4uKiNWvWqG/fvkpOTnZ0uQCuIYQkAE7H19dXAwcO1LvvvqtVq1bJ09NTycnJGjdunKNLA3ANISQBcGoDBw7UnDlzJEl79uzRxo0brZbv2bNHs2fP1sCBA9WhQwc1b95cbdu21ciRI7VmzZpy6zt58qR8fX21YMECSVJ8fLx8fX2tvk6ePGkZf+LECb355pu69957FRERoZYtWyo0NFQDBw7Um2++qby8PDtuPQBH4sZtAE4vKipKixYt0pkzZ/Txxx9r6NChkqTs7GwNHDjQMs7d3V2enp5KT0/Xli1btGXLFkVHR+tvf/ubZYyrq6tatGihnJwc5eTkyNPTU02bNrX6ea6urpbvo6OjdeDAAUmSi4uLmjZtqqysLO3Zs0d79uzRp59+qrVr16pJkyb23AUAHIAzSQCcnoeHh/r27StJ2rlzp6W/UaNGGjx4sJYtW6YjR44oLS1NSUlJOnHihBYuXCgfHx/94x//0GeffWaZExwcrMTERD399NOSpBEjRljuiSr7Cg4OtoyPiIjQq6++qv379ystLU0nT55Uamqq4uPj1bZtW+3fv1+zZ8+uoz0BoC5xJglAvXDrrbdKkpKTk1VYWCh3d3d5e3tr1apV5cb6+vpq/Pjxatq0qZ566im98847Gj58+FX93DfeeKNcX+PGjTV06FB16NBBXbt21QcffKCXX35Z3t7eV/UzADgnziQBqBd8fX0t358/f75ac4YMGSLp8n1LxcXFNq8pLCxMt9xyi3Jzc3X48GGbrx+AY3EmCUC94+LiYvm+qKhIH3zwgdasWaP//Oc/On/+vAoKCqzG5+fnKzMzU35+flf1877++mu9//772rt3r9LS0ow3a6empl7VugE4L0ISgHohMzPT8n3ZWaXs7GyNHDlS3333nWWZl5eX/P391ajR5RPlZ86ckSTl5ORcVUh64YUXtHTpUkvb3d1dzZo1k7u7u6TLZ7UKCwuVk5NT840C4NQISQDqhR9//FGSFBQUZAkoixYt0nfffSc/Pz/NnTtXAwcOVPPmzS1ziouLLcGotLS0xj/zyy+/1NKlS+Xq6qqpU6dqzJgxCgsLszqTNXToUO3cufOq1g/AuRGSADi9goICbd26VZLUo0cPS3/ZU2sLFy7UyJEjy80rO4t0tcrWP27cOL344ovGMbX9GQCcFzduA3B6y5cv19mzZyVJo0ePtvSXfUxJRESEcd4333xT4TrLLsdVdgaoqvWfOnVKv/zyS8WFA6jXCEkAnNqWLVv00ksvSbr8OW/33HOPZVnZSyDLLsX9VnZ2tv76179WuN6ylz9euHChwjGVrV+S5syZw2U2oAEjJAFwOhcuXNCWLVv0+OOPa/To0crLy1NwcLCWL19uNa5///6SpJkzZ2rHjh2WwLJv3z7dd999ysjIqPBndOjQQZK0a9cu/fzzz8YxZet/7733tHLlSstTc0lJSXrqqaf08ccfW72aAEDD4pKZmck/gwDUuQkTJig+Pt7ytFiZ7Oxs5ebmWtouLi4aPny4YmJiyj2dduLECd19992WMOTp6SlXV1fl5OTIy8tL//znP3X//fdLkg4ePKjWrVtb5hYWFqp79+46fvy4XFxc5OfnJy8vL0nSF198oaCgIBUUFGjYsGHavXu3pMsfV+Lj42M5+zRjxgxt3bpVCQkJWrx4scaOHWuHPQXAUTiTBMChCgsLdebMGZ05c0YZGRny8PBQWFiYhg4dqlmzZmn//v167733jI/vh4WFacuWLXrggQfUvHlzFRcX6/rrr9cDDzygr776SgMGDKjw57q7u2vNmjUaM2aMAgMDlZmZqaSkJCUlJamoqEjS5Y9D+eyzz/Tss88qLCxMjRo1kpubm/r3768PP/xQL7zwgt32CwDHc/iZpGPHjmnhwoU6ePCgUlNTVVhYqODgYA0aNEiTJk1Sq1atqlzHsGHDlJCQYFz29ddfq3PnzrYuGwAANHAOfwVAcnKyUlNTFRkZqcDAQLm5uemHH37Q8uXL9emnn2r79u1W7z2piJ+fn1555ZVy/WFhYXaoGgAANHQOD0n9+vVTv379yvX36tVL0dHR+uCDD/TMM89UuR5vb2+NGTPGHiUCAIBrkNPekxQSEiLJ+qMIqlJSUqKsrCweyQUAALXmNCEpPz9fGRkZOn36tL766itNnjxZkjRo0KBqzU9JSVFQUJBCQ0MVFBSkhx9+WImJifYsGQAANGAOv9xWZsWKFVZPioSGhmrp0qXq2bNnlXNbt26tO++8U+Hh4XJ1ddWePXsUFxenbdu2aePGjQoPD7dn6QAAoAFy+NNtZU6fPq1jx44pOztbhw4d0saNG/XQQw/p//2//3dV6/v2228VGRmpvn37Wj5/CQAAoLqcJiRd6T//+Y8GDBigF198UVOmTLmqdURGRmrnzp369ddfLS+JAwAAqA6nuSfpSh07dlRERISWLVt21esIDQ1VcXFxjW7+BgAAkJw4JElSXl6ezp8/f9Xzf/nlF7m5uVl95AEAAEB1ODwkpaWlGfu3bdumI0eOqGvXrpa+1NRUJSYmWn2u04ULF1RcXFxu/qZNm7Rr1y71799fnp6eti8cAAA0aA6/J2ns2LFKS0tT3759FRISovz8fB04cECffvqpvLy8tH79ekVEREj63wdirlu3Tn369JEkrV+/XjNnztSQIUMUFhYmNzc37d27V6tWrVKzZs20adMmtW3b1pGbCAAA6iGHvwJg1KhRio+P17/+9S+lp6fLxcVFISEhio6O1qRJkywvlaxIu3btdPvtt2vTpk06e/asCgsLFRgYqMcee0xTpkxRYGBgHW0JAABoSBx+JgkAAMAZOfyeJAAAAGdESAIAADAgJAEAABgQkgAAAAwISQAAAAaEJAAAAANCEgAAgAEhCQAAwICQBAAAYEBIAgAAMCAkAQAAGBCSAAAADAhJAAAABoQkAAAAA0ISAACAASEJAADAgJAEAABgQEgCAAAwICQBAAAYEJIAAAAMCEkAAAAGhCQAAAADQhIAAIABIQkAAMCAkAQAAGBASAIAADAgJAEAABgQkgAAAAwISQAAAAaEJAAAAANCEgAAgAEhCQAAwICQBAAAYEBIAgAAMCAkAQAAGBCSAAAADAhJAAAABoQkAAAAA0ISAACAASEJAADAwM3RBQBAQ1NSWqKj545qX+o+7Uu7/PVD+g8qKC6wjFk8aLHGho91YJVwVhw/zoOQBAA2subYGi09sFQHzxxUdmG2o8tBPcPx43wISQBgIztP71TC6QRHl4F6iuPH+XBPEgDYWVOPpgr0CXR0GainOH4chzNJAGBDXm5e6tS8kzq37KwuLbuoS8suatusrebvmq8F3y1wdHlwchw/zoWQBAA28nz35zW371y5NeJXK2qO48f58F8CAGzE39vf0SWgHuP4cT7ckwQAAGBASAIAADAgJAEAABgQkgAAAAwISQAAAAaEJAAAAAOHh6Rjx47piSeeUPfu3RUaGqqAgAB169ZNM2bMUGpqarXXs3nzZg0ePFiBgYEKCwtTVFSUTpw4Yb/CAQBAg+bw9yQlJycrNTVVkZGRCgwMlJubm3744QctX75cn376qbZv367mzZtXuo61a9cqKipKHTt21Msvv6ysrCwtWbJEQ4YM0ddff62AgIA62hoAANBQODwk9evXT/369SvX36tXL0VHR+uDDz7QM888U+H8wsJCTZs2TUFBQdq4caN8fHwkSQMHDtRdd92l+fPn6+9//7vd6gcAAA2Twy+3VSQkJESSlJmZWem4hIQEpaSkaNy4cZaAJEkRERHq3bu3Vq9ercLCQrvWCgAAGh6nCUn5+fnKyMjQ6dOn9dVXX2ny5MmSpEGDBlU6b9++fZKk7t27l1vWrVs3ZWVl6aeffrJ9wQAAoEFzmpC0YsUK3XTTTQoPD9f999+vCxcuaOnSperZs2el81JSUiTJeN9RWV/ZGAAAgOpy+D1JZYYNG6b27dsrOztbhw4d0saNG5Wenl7lvLy8PElS48aNyy0r68vNzbVtsQAAoMFzmpAUFBSkoKAgSVJkZKTuvfdeDRgwQPn5+ZoyZUqF87y8vCRJly5dKresrM/b29sOFQMAgIbMaS63Xaljx46KiIjQsmXLKh1X2SW1yi7FAQAAVMZpQ5J0+VLa+fPnKx3TpUsXSdL3339fbtnu3bvVtGlTtW3b1i71AQCAhsvhISktLc3Yv23bNh05ckRdu3a19KWmpioxMdHqHqNevXqpVatWWrFihbKzsy39hw8f1o4dO3TffffJ3d3dfhsAAAAaJIffkzRlyhSlpaWpb9++CgkJUX5+vg4cOKBPP/1UPj4+mjt3rmXs7NmzFR8fr3Xr1qlPnz6SJHd3d82fP1+PPvqohg4dqqioKF28eFGxsbHy9/fX9OnTHbVpAACgHnN4SBo1apTi4+P1r3/9S+np6XJxcVFISIiio6M1adIky0slKzN8+HB5enoqJiZGs2bNkoeHh/r166fZs2crMDCwDrYCAAA0NA4PSSNGjNCIESOqNXbJkiVasmSJcdmQIUM0ZMgQW5YGADV28sJJY/+FSxes2ufyzxnHerp5quV1Le1SG5wfx49zccnMzCx1dBEA0FD4/s23VvN7BfXShtEbbFQN6huOH+fi8Bu3AQAAnBEhCQAAwIDLbQAAAAacSQIAADAgJAEAABgQkgAAAAwISQAAAAaEJAAAAANCEgAAgAEhCQAAwICQBAAAYEBIAgAAMCAkAQAAGBCSAAAADAhJAAAABoQkAAAAA0ISAACAASEJAADAgJAEAABgQEgCAAAwICQBAAAYEJIAAAAMCEkAAAAGhCQAAAADQhIAAIABIQkAAMCAkAQAAGBASAIAADAgJAEAABgQkgAAAAwISQAAAAaEJAAAAANCEgAAgAEhCQAAwICQBAAAYEBIAgAAMCAkAQAAGBCSAAAADAhJAAAABoQkAAAAA0ISAACAASEJAADAgJAEAABgQEgCAAAwICQBAAAYEJIAAAAMCEkAAAAGhCQAAAADQhIAAIABIQkAAMCAkAQAAGBASAIAADBweEj66aefNG/ePA0cOFA33XSTgoOD1bt3b8XExCgnJ6da6xg2bJh8fX2NX/v377fzFgAAgIbIzdEFvP/++3rnnXc0dOhQjR49Wu7u7tq+fbvmzp2r1atX69///re8vLyqXI+fn59eeeWVcv1hYWF2qBoAADR0LpmZmaWOLGD//v268cYbdf3111v1z507VzExMVq4cKHGjx9f6TqGDRumU6dO6fDhw/YsFQAAXEMcfrmtc+fO5QKSJI0YMUKSdOTIkWqvq6SkRFlZWSotdWjuAwAADYDDQ1JFkpOTJUnNmzev1viUlBQFBQUpNDRUQUFBevjhh5WYmGjPEgEAQAPm8HuSTIqLi7Vw4UK5ublp9OjRVY5v3bq17rzzToWHh8vV1VV79uxRXFyctm3bpo0bNyo8PLwOqgYAAA2Jw+9JMpk6dari4uL00ksvacqUKVe1jm+//VaRkZHq27evPvvsMxtXCAAAGjqnu9w2d+5cxcXFKTo6+qoDkiT17NlTPXv21Pbt25WXl2fDCgEAwLXAqULSq6++qpiYGI0dO1avv/56rdcXGhqq4uJiZWZm2qA6AABwLXGakDR//nwtWLBADz74oN588025uLjUep2//PKL3Nzc1KxZMxtUCAAAriVOEZIWLFig+fPna8yYMYqNjVWjRuayUlNTlZiYqNzcXEvfhQsXVFxcXG7spk2btGvXLvXv31+enp52qx0AADRMDr9xOy4uTlOnTlVwcLBmzpxZLiC1aNFC/fv3lyRNmDBB8fHxWrdunfr06SNJWr9+vWbOnKkhQ4YoLCxMbm5u2rt3r1atWqVmzZpp06ZNatu2bZ1vFwAAqN8c/gqAffv2SZJ+/fVXTZgwodzyXr16WUKSSbt27XT77bdr06ZNOnv2rAoLCxUYGKjHHntMU6ZMUWBgoN1qBwAADZfDzyQBAAA4I6e4JwkAAMDZEJIAAAAMCEkAAAAGhCQAAAADQhIAAIABIQkAAMCAkAQAAGBASAIAADAgJAEAABgQkgAAAAwISQAAAAaEJAAAAANCEgAAgAEhCQAAwICQBAAAYEBIAgAAMCAkAQAAGBCSAAAADAhJAAAABoQkAAAAA0ISAACAASEJAADAgJAEAABgQEgCAAAwICQBAAAYEJIAAAAMCEkAAAAGhCQAAAADQhIAAIABIQkAAMCAkAQAAGBASAIAADAgJAEAABgQkgAAAAwISQAAAAaEJAAAAANCEgAAgAEhCQAAwMDN0QUAQENXVFKk75K/06msU0rLSVMTjyYKbBKo7gHd5efl5+jyAFSAkARUoKS0REfPHdW+1H3al3b564f0H1RQXGAZs3jQYo0NH+vAKuHMcgtztei7Rfrnj//Umdwz5Za7N3LXoLBBmtlzpsL9wx1QIYDKEJKAK6w5tkZLDyzVwTMHlV2Y7ehyUE8dyTiiqPVRSjyfWOGYwpJCff7L5/rq5Fd6pd8reizisTqsEEBVCEnAFXae3qmE0wmOLgP1WGpOqkauHqnk7GSr/ttb3K6w68N0Lv+c9qft18WCi5Kk/OJ8Tflqinw8fPTALQ84omQABoQkoJqaejSVj4dPuT98wG+VlpZq3PpxVsfJrf63auk9S9WxeUdLX2Z+pubtnKe4g3GWvklfTlKn5p3Uwa9DndYMwIyn2wADLzcvdQ/oridvf1Jv3/O2do/brZMTTuqR8EccXRqc3Nqf1ur7lO8t7dZNW+vzUZ9bBSRJ8vX01aL+i/Tk7U9a+vKL8zXv23l1ViuAynEmCbjC892f19y+c+XWiP89UHMLvltg1Y7pHyNfT98Kx/9fr//T5z9/rqSLSZKk9T+v16EzhxTRIsKudQKoGmeSgCv4e/sTkHBVfkj/QT+m/2hpt2/WXoPaDKp0jre7d7kbtj8++rFd6gNQM4QkALCRL375wqr9QIfq3YQ9+pbRVu2Nv2y0WU0Arh4hCQBs5OtTX1u1ewT2qNa84CbBCmkSYmkfO39MSVlJNq0NQM0RkgDARv6b8V/L941cGqlzy87VntstoJtV++i5ozarC8DVISQBgA1k5mcqPS/d0m7h3ULe7t7Vnt+6aWur9rHzx2xWG4CrQ0gCABs4fuG4VTvIJ6hG8wObBFq1f8n8pdY1AagdQhIA2EDWpSyrtr+3f43m+3tZj88qyKpgJIC64vCQ9NNPP2nevHkaOHCgbrrpJgUHB6t3796KiYlRTk5OtdezefNmDR48WIGBgQoLC1NUVJROnDhhv8IB4Deu/Jy/xq6NazTf083Tqp1TUP3ffwDsw+Eh6f3339eSJUvUpk0bvfDCC3r55ZfVrl07zZ07V4MHD1ZeXl6V61i7dq3GjBmjvLw8vfzyy5o0aZK+/fZbDRkyRCkpKXWwFQCudbmFuVbtK0NPVTxdrcdfuT4Adc/hb8y777779Oyzz+r666+39D322GO66aabFBMTo5UrV2r8+PEVzi8sLNS0adMUFBSkjRs3ysfHR5I0cOBA3XXXXZo/f77+/ve/2307AKA2XFxcrNqlKnVQJQDKOPxMUufOna0CUpkRI0ZIko4cOVLp/ISEBKWkpGjcuHGWgCRJERER6t27t1avXq3CwkLbFg0AV7jySbb8ovwazc8rsj5rfp37dbWuCUDtODwkVSQ5+fInaDdv3rzScfv27ZMkde/evdyybt26KSsrSz/99JPtCwSA37gy1FwqvlSj+ZeKrMdf50FIAhzNKUNScXGxFi5cKDc3N40ePbrSsWX3HAUEBJRbVtbHfUkA7K2pR1OrdkZeRo3m//YdS6b1Aah7ThmSXnzxRe3evVszZsxQu3btKh1bdmN348blnyQp68vN5QZIAPZ1o++NVu3TF0/XaP6V49tc36bWNQGoHacLSXPnzlVcXJyio6M1ZcqUKsd7eXlJki5dKn9qu6zP27v6b70FgKvh6+lr9a6jtNy0Gj2hdjLrpFW7/Q3tbVYbgKvjVCHp1VdfVUxMjMaOHavXX3+9WnMqu6RW2aU4ALC1W/xusXxfUlqi/Wn7qz13T+oeq/bNN9xss7oAXB2nCUnz58/XggUL9OCDD+rNN98s9zhsRbp06SJJ+v7778st2717t5o2baq2bdvatFYAMLkr9C6r9s7kndWad/riaZ3KOmVpt2vWTiFNQ2xZGoCr4BQhacGCBZo/f77GjBmj2NhYNWpkLis1NVWJiYlW9xj16tVLrVq10ooVK5Sd/b833h4+fFg7duzQfffdJ3d3d7tvAwAMvXGoVfuj/35UrXmr/ruq0vUAcAyHv0wyLi5Or776qoKDg3XXXXfpo4+sf6m0aNFC/fv3lyTNnj1b8fHxWrdunfr06SNJcnd31/z58/Xoo49q6NChioqK0sWLFxUbGyt/f39Nnz69zrcJwLUp3D9ct/rdqh8zfpQkHT13VF8e/1KD2gyqcE5eUZ7ePfSuVd/Im0fatU4A1ePwkFT2nqNff/1VEyZMKLe8V69elpBUkeHDh8vT01MxMTGaNWuWPDw81K9fP82ePVuBgYGVzgUAW5p25zRFbYiytKd+M1XfBHwjX09f4/jZO2Yr6WKSpT3spmG6rcVtdq8TQNVcMjMzefc9cIWTF04a+5fsX6K3Drxlac/pM0f3tr233DhPN0+1vK6l3eqD8yotLdU9q+7R9yn/u0/yVv9bFTckTuH+4Za+C5cuaO63cxV3MM7S5+nqqa//+LU6+HWo05oBmBGSAAPfv5n/1V9dvYJ6acPoDTaqBvVNSnaKBsQPUErO/566dZGLbm95u8Kahulc/jntS9uniwUXreYtHbJUD9zyQF2XC6ACTnHjNgA0JAE+AfpkxCdq1+x/L8MtVan2p+3X6mOrtTVpq1VA8nT11F/7/5WABDgZQhIA2MGt/rdq6x+3anLXyWrubf4MSvdG7hpy4xBteWiLHr/t8TquEEBVuNwGAHZWVFKkXcm7dPLCSZ3JPaMmHk0U6BOo7gHd5e/tX/UKADgEIQkAAMCAy20AAAAGhCQAAAADQhIAAIABIQkAAMCAkAQAAGBASAIAADAgJAEAABgQkgAAAAwISQAAAAaEJAAAAANCEgAAgAEhCQAAwMCtugMPHjyoHTt2yM3NTQMGDFC7du2M4zZs2KDPP/9cixcvtlmRAAAAda1aIenPf/6zYmNjLW0XFxc9/vjjmjdvntzd3a3GHj58WPHx8YQkAABQr1V5uW3dunVavHixfHx8NG7cOD3++OPy9/fXO++8oxEjRig3N7cu6gQAAKhTVYakd999V56entqyZYv+9re/adGiRdqzZ4/uvfdeJSQkaMyYMcrPz6+LWgEAAOpMlSHp4MGD+sMf/mB1D1KTJk30j3/8QxMmTNCOHTv04IMP6tKlS3YtFAAAoC5VGZJycnIUEhJiXPbKK6/o6aef1tatWzV27FgVFBTYvEAAAABHqPLG7ZYtWyotLa3C5XPmzFFRUZHeeustPfLII+rYsaNNCwQAAHCEKkPSzTffrISEhErHvPrqqyosLNSyZcu0Y8cOmxUHAADgKFVebhs4cKBOnDihb7/9ttJxMTExeuSRR3jaDQAANAhVnkm69957lZqaqnPnzlW5sjfeeEOBgYE6deqUTYoDAABwFJfMzMxSW6+0qKhIbm7Vfpk3AACA06nRZ7c988wzVb4T6eTJkxoyZEitigIAAHC0GoWkFStWaMCAAUpMTDQuX7Nmjfr27at9+/bZpDgAAABHqVFIeu6553T06FH1799f77//vqW/oKBAzz33nB599FG5urpaLQMAAKiPanxP0tatWzV+/HidPXtWo0aN0oQJEzRx4kT98MMPuvPOO/XOO+8oKCjIXvUCAADUiau6cfvs2bN68skn9c0330iSGjVqpGeffVbTp09Xo0Y1OjkFAADglK7qEbTrrrtO/v7+Ki29nK+aNm2qXr16EZAAAECDUeNUc/jwYfXr108ff/yx7r77br3++usqLCzUyJEjNWfOHJWUlNijTgAAgDpVo5AUFxenwYMH68SJE3rppZf08ccfKzo6Wt98843Cw8P1+uuva+jQoUpKSrJXvQAAAHWiRvckNWvWTMHBwVq2bJm6d+9utaygoEAzZ87UO++8I19fXx0/ftzmxQIAANSVGp1J+v3vf6/t27eXC0iS5OHhoUWLFmnlypU2Kw4AAMBR7PKxJL/++quCg4NtvVoAAIA6Y5eQBAAAUN/xzD4AAIABIQkAAMCAkAQAAGBASAIAADAgJAEAABgQkgAAAAwISQAAAAaEJAAAAANCEgAAgAEhCQAAwICQBAAAYEBIAgAAMCAkAQAAGLg5uoDXXntNBw8e1IEDB3Ty5EmFhITo8OHDNVpHp06dlJSUZFz2888/y8/PzxalAgCAa4jDQ9LLL7+sZs2a6bbbbtOFCxeuej3t27fXc889V67fx8enNuUBAIBrlMND0oEDBxQWFiZJ6tGjh7Kzs69qPc2bN4zbmKgAAB41SURBVNeYMWNsWBkAALiWOfyepLKAZAtFRUXKysqy2foAAMC1y+EhyVb27t2rgIAAhYaGKjQ0VE899ZRSUlIcXRYAAKinHH65zRY6dOigcePGqX379ioqKtKOHTu0YsUKbdu2TVu2bFFAQICjSwQAAPWMS2ZmZqmjiyhTdk9STZ9uM/noo4/0xBNPaNy4cXrjjTdsUB0AALiWNJjLbVcaPXq0QkNDtXnzZkeXAgAA6qEGG5IkKTQ0VBkZGY4uAwAA1EMNOiQdP35cLVq0cHQZAACgHqpXISkpKUmJiYkqLCy09J0/f944Ni4uTqdPn9aQIUPqqjwAANCAOPzptg8//NDykSLp6ekqKCjQokWLJEkhISF68MEHLWOfeuopJSQk6ODBg2rdurUkKT4+Xu+//77uvvtuhYaGWp5u27Bhg9q0aaPp06fX/UYBAIB6z+EhaeXKlUpISLDqmzdvniSpV69eViHJpEuXLtq2bZtWr16t9PR0lZaWqnXr1po8ebImT54sX19fu9UOAAAaLqd6BQAAAICzqFf3JAEAANQVQhIAAIABIQkAAMCAkAQAAGBASAIAADAgJAEAABgQkgAAAAwISQAAAAaEJAAAAANCEgAAgAEhCQAAwICQBAAAYEBIAgAAMCAkAQAAGBCSAAAADAhJAAAABoQkAAAAA0ISAACAASEJAADAgJAEAABgQEgCAAAwICQBAAAYEJIAAAAMCEkAAAAGhCQAAAADQhIAAIABIQkAAMCAkAQAAGBASAIAADAgJAEAABgQkgAAAAwISQAAAAaEJAAAAANCEgAAgAEhCQAAwICQBAAAYEBIAgAAMCAkAQAAGLg5ugCgvigqKdJ3yd/pVNYppeWkqYlHEwU2CVT3gO7y8/JzdHkAABsjJAFVyC3M1aLvFumfP/5TZ3LPlFvu3shdg8IGaWbPmQr3D3dAhXA2JaUlOnruqPal7tO+tMtfP6T/oILiAsuYxYMWa2z4WAdWCaAqhCSgEkcyjihqfZQSzydWOKawpFCf//K5vjr5lV7p94oei3isDiuEM1lzbI2WHliqg2cOKrsw29HlAKglQhJQgdScVI1cPVLJ2clW/be3uF1h14fpXP457U/br4sFFyVJ+cX5mvLVFPl4+OiBWx5wRMlwsJ2ndyrhdIKjywBgI4QkwKC0tFTj1o+zCki3+t+qpfcsVcfmHS19mfmZmrdznuIOxln6Jn05SZ2ad1IHvw51WjOcV1OPpvLx8CkXuAE4N55uAwzW/rRW36d8b2m3btpan4/63CogSZKvp68W9V+kJ29/0tKXX5yved/Oq7Na4Vy83LzUPaC7nrz9Sb19z9vaPW63Tk44qUfCH3F0aQBqiDNJgMGC7xZYtWP6x8jX07fC8f/X6//0+c+fK+likiRp/c/rdejMIUW0iLBrnXAuz3d/XnP7zpVbI361Ag0BZ5KAK/yQ/oN+TP/R0m7frL0GtRlU6Rxvd+9yN2x/fPRju9QH5+Xv7U9AAhoQQhJwhS9++cKq/UCH6t2EPfqW0Vbtjb9stFlNAIC6R0gCrvD1qa+t2j0Ce1RrXnCTYIU0CbG0j50/pqSsJJvWBgCoO4Qk4Ar/zfiv5ftGLo3UuWXnas/tFtDNqn303FGb1QUAqFuEJOA3MvMzlZ6Xbmm38G4hb3fvas9v3bS1VfvY+WM2qw0AULcIScBvHL9w3Kod5BNUo/mBTQKt2r9k/lLrmgAAjkFIAn4j61KWVdvf279G8/29rMdnFWRVMBIA4OycIiS99tprioqK0m233SZfX1916tTpqtYTHx+vPn36qFWrVmrXrp0mTpyo9PT0qicC/78rP2+rsWvjGs33dPO0aucU5NS6JgCAYzhFSHr55Ze1bds2tWnTRr6+Fb+wrzKLFy/WhAkT1LRpU82fP1/R0dH69NNPFRkZqZwc/lChenILc63aV4aeqni6Wo+/cn0AgPrDKd56duDAAYWFhUmSevTooezsmn16dkZGhubNm6cuXbpo7dq1cnV1lSR16dJFDz30kN566y0999xzti4bKMfFxcWqXapSB1UCAKgtpziTVBaQrtaGDRuUm5ur8ePHWwKSJA0dOlRhYWFatWpVLSvEteLKJ9nyi/JrND+vKM+qfZ37dbWuCQDgGE4Rkmpr3759kqTu3buXW9atWzclJibW+OwUrk1XhppLxZdqNP9SkfX46zwISQBQXzWIkJSSkiJJCggIKLcsICBApaWlSk1NreuyUA819Whq1c7Iy6jR/N++Y8m0PgBA/dEgQlJe3uVLHI0bl38SqawvN5cbaFG1G31vtGqfvni6RvOvHN/m+ja1rgkA4BgNIiR5eXlJki5dKn9ppKzP27v6b03GtcvX09fqXUdpuWk1ekLtZNZJq3b7G9rbrDYAQN1qECGp7DJb2WW330pJSZGLi4tatWpV12WhnrrF7xbL9yWlJdqftr/ac/ek7rFq33zDzTarCwBQtxpESOrSpYsk6fvvvy+3bM+ePWrXrp18fHzquizUU3eF3mXV3pm8s1rzTl88rVNZpyztds3aKaRpiC1LAwDUoXoXkpKSkpSYmKjCwkJL3+9//3t5eXkpLi5OxcXFlv6NGzfq+PHjGj16tCNKRT019MahVu2P/vtRteat+q/1qyauXA8AoH5xipdJfvjhh0pKSpIkpaenq6CgQIsWLZIkhYSE6MEHH7SMfeqpp5SQkKCDBw+qdevLn7ju7++vGTNmaNasWbrvvvs0atQoJScna/HixWrfvr0mTJhQ9xuFeivcP1y3+t2qHzN+lCQdPXdUXx7/UoPaDKpwTl5Rnt499K5V38ibR9q1TgCAfTlFSFq5cqUSEhKs+ubNmydJ6tWrl1VIqsjEiRN1ww03KDY2VtOmTVOTJk00fPhw/eUvf+FSG2ps2p3TFLUhytKe+s1UfRPwjXw9zR+bM3vHbCVdTLK0h900TLe1uM3udQIA7MclMzOTz00ArlBaWqp7Vt2j71P+d5/brf63Km5InML9wy19Fy5d0Nxv5yruYJylz9PVU1//8Wt18OtQpzXDOZy8cNLYv2T/Er114C1Le06fObq37b3lxnm6earldS3tVh+A6iMkARVIyU7RgPgBSsn531OTLnLR7S1vV1jTMJ3LP6d9aft0seCi1bylQ5bqgVseqOty4SR8/3Z1H9JdpldQL20YvcFG1QCojXp34zZQVwJ8AvTJiE/Urlk7S1+pSrU/bb9WH1utrUlbrQKSp6un/tr/rwQkAGggCElAJW71v1Vb/7hVk7tOVnPv5sYx7o3cNeTGIdry0BY9ftvjdVwhAMBeuNwGVFNRSZF2Je/SyQsndSb3jJp4NFGgT6C6B3SXv7d/1SsAANQrhCQAAAADLrcBAAAYEJIAAAAMCEkAAAAGhCQAAAADQhIAAIABIQkAAMCAkAQAAGBASAIAADAgJAEAABgQkgAAAAwISQAAAAaEJAAAAANCEgAAgAEhCQAAwICQBAAAYEBIAgAAMCAkAQAAGBCSAAAADAhJAAAABoQkAAAAA0ISAACAASEJAADAgJAEAABgQEgCAAAwICQBAAAYEJIAAAAMCEkAAAAGhCQAAAADQhIAAIABIQkAAMCAkAQAAGBASAIAADAgJAEAABgQkgAAAAwISQAAAAaEJAAAAANCEgAAgAEhCQAAwICQBAAAYEBIAgAAMCAkAQAAGBCSAAAADAhJAAAABoQkAAAAA0ISAACAASEJAADAgJAEAABgQEgCAAAwcIqQVFJSosWLF6tbt25q2bKlwsPDNXPmTOXk5FRrvq+vr/ErKCjIzpUDAICGys3RBUjS9OnT9fbbbysyMlJPP/20jh49qrfffluHDh3SmjVr1KhR1VmuR48eio6Otupzd3e3U8UAAKChc3hIOnLkiJYuXao//OEPWrlypaW/devWmjZtmj755BONHj26yvWEhYVpzJgx9iwVAABcQxx+ue2TTz5RaWmpJkyYYNUfFRUlb29vrVq1qtrrKigoUHZ2tq1LBAAA1yCHh6R9+/apUaNGuuOOO6z6PT091alTJ+3bt69a61m7dq0CAgIUHBystm3baurUqbpw4YI9SgYAANcAh19uS01NlZ+fnxo3blxuWUBAgL777jsVFBTIw8OjwnXccccdGj58uNq0aaOLFy/qyy+/VFxcnBISErR582b5+PjYcxMAAEAD5PCQlJubawxIkiz9ubm5lYakLVu2WLUfeughhYeHa86cOXrrrbf0/PPP265gAABwTXD45TZvb29dunTJuKys39vbu8brnTRpkjw8PLR58+Za1QcAAK5NDg9JrVq1UkZGhjEopaSkyM/Pr9KzSBVxd3e3rBsAAKCmHB6SunTpopKSEu3du9eqPz8/X4cPH1bnzp2var35+flKTk5WixYtbFEmAAC4xjg8JI0YMUIuLi5asmSJVf/y5cuVm5tr9Y6k48ePKzEx0WrcuXPnjOudN2+eioqKNGTIENsXDQAAGjyXzMzMUkcXMXXqVMXFxSkyMlKDBw+2vHH7d7/7ndatW2d543anTp2UlJSkzMxMy9zp06drz5496tOnj4KDg5WTk6PNmzdr+/bt6tq1q9atWycvLy9HbRoAAKinnCIkFRcXKzY2VsuXL9epU6fk5+enESNGaMaMGVaP75tC0oYNG7Rs2TIdOXJE586dk6urq2688UaNGDFCf/rTn+Tp6emITQIAAPWcU4QkAAAAZ+Pwe5IAAACcESEJAADAgJAEAABgQEgCAAAwICQBAAAYEJIAAAAMCEkAAAAGhCQAAAADQhIAAIABIQkAAMCAkAQAAGBASAIAADAgJAEAABgQkgAAAAwISQAAAAaEJAAAAANCEgAAgAEhCQAAwICQBAAAYEBIAgAAMCAkAQAAGBCSAAAADAhJAAAABoQkAAAAA0ISAACAASEJAADAgJAEAABgQEgCAAAwICQBAAAYEJIAAAAMCEkAAAAGhCQAAAADQhIAAIABIQkAAMCAkAQAAGBASAIAADAgJAEAABgQkgAAAAwISQAAAAaEJAAAAANCEgAAgAEhCQAAwICQBAAAYEBIAgAAMCAkAQAAGBCSAAAADAhJAAAABoQkAAAAA0ISAACAASEJAADAgJAEAABgQEgCAAAwICQBAAAYOEVIKikp0eLFi9WtWze1bNlS4eHhmjlzpnJycupkPgAAwJVcMjMzSx1dxLRp0/T2228rMjJSgwYN0tGjR7V06VL16NFDa9asUaNGlWe52s4HAAC4kpujCzhy5IiWLl2qP/zhD1q5cqWlv3Xr1po2bZo++eQTjR492m7zAQAATBx+iuWTTz5RaWmpJkyYYNUfFRUlb29vrVq1yq7zAQAATBwekvbt26dGjRrpjjvusOr39PRUp06dtG/fPrvOBwAAMHF4SEpNTZWfn58aN25cbllAQIAyMjJUUFBgt/kAAAAmDg9Jubm5xoAjydKfm5trt/kAAAAmDg9J3t7eunTpknFZWb+3t7fd5gMAAJg4PCS1atVKGRkZxqCTkpIiPz8/eXh42G0+AACAicNDUpcuXVRSUqK9e/da9efn5+vw4cPq3LmzXecDAACYODwkjRgxQi4uLlqyZIlV//Lly5Wbm2v1jqPjx48rMTHROD82Ntbqrds333yzcnNzde+991arjob+1u7abp+vr6/xKygoyM6V299rr72mqKgo3XbbbfL19VWnTp2uaj3x8fHq06ePWrVqpXbt2mnixIlKT0+3cbV1zxb7p1OnThUeQxkZGXaoum789NNPmjdvngYOHKibbrpJwcHB6t27t2JiYmr0u2Pz5s0aPHiwAgMDFRYWpqioKJ04ccJ+hdcBW+ybYcOGVXjc7N+/385bYF/Hjh3TE088oe7duys0NFQBAQHq1q2bZsyYodTU1GqvpyEeO5Jt9o8tjh+neOP21KlTFRcXp8jISA0ePFhHjx7V22+/rd/97ndat26d5Y3ZnTp1UlJSkjIzM43zJSkiIkI33HCDtm3bppKSEvXu3Vtr16695t/aXdvt8/X1VY8ePRQdHW3V7+7urvvvv9+Oldufr6+vmjVrpttuu00HDhxQkyZNdPjw4RqtY/HixZo5c6Z69eql0aNH6/Tp04qNjVVISIi2bNmi6667zk7V258t9k+nTp3k5eWl5557rtyy4cOHV/jwhbP7y1/+onfeeUdDhw5V165d5e7uru3bt2v16tUKDw/Xv//9b3l5eVW6jrVr1yoqKkodO3ZUVFSUsrKytGTJErm6uurrr79WQEBAHW2Nbdli3wwbNkz//e9/9corr5RbNnjwYDVr1sxe5dvd1q1bFRMTo27duikwMFBubm764Ycf9MEHH6hJkybavn27mjdvXuk6GuqxI9lm/9ji+HGKkFRcXKzY2FgtX75cp06dkp+fn0aMGKEZM2bIx8fHMq6ikPSf//xHvXv31nXXXafCwkLL/FatWumll15SXFxclW/t7tmzpyIjI63e2v32229r2rRpVc53drbYPl9fXz300EPlzvg1BCdOnFBYWJgkqUePHsrOzq5RCMjIyFCnTp10yy236Msvv5Srq6skaePGjXrooYc0a9YsYzioL2q7f6TL/++GhoZqw4YNdqjQcfbv368bb7xR119/vVX/3LlzFRMTo4ULF2r8+PEVzi8sLFRERIRcXV21a9cuy++7Q4cO6a677tIjjzyiv//973bdBnup7b6RLv+RO3XqVI2Pt/rss88+U3R0tGbPnq1nnnmmwnEN+dipTHX3j2Sb48cpTo+4urpq4sSJ2rNnj86cOaMjR47olVdesQpIknT48OFyAUm6vNMk6aOPPrKaP378eN7aLdtuX0FBgbKzs21dokOVBYCrtWHDBuXm5mr8+PGWgCRJQ4cOVVhYWL0/fmq7f36rqKhIWVlZNlufo3Xu3LlcCJAu3wYgXf4HSmUSEhKUkpKicePGWf2+i4iIUO/evbV69WoVFhbatug6Utt981slJSXKyspSaanD/01vdyEhIZJk/Fv3Ww352KlMdffPb9Xm+HGKkFRbvLW7crbavrVr1yogIEDBwcFq27atpk6dqgsXLtij5HqlbP9179693LJu3bopMTGxwQXLq7F3714FBAQoNDRUoaGheuqpp5SSkuLosuwiOTlZkqq8HFDVsZOVlaWffvrJ9gU6UHX3TZmUlBQFBQUpNDRUQUFBevjhh8vdm1qf5efnKyMjQ6dPn9ZXX32lyZMnS5IGDRpU6bxr5di52v1TprbHj8M/4NYWqnrr9nfffaeCgoIKXwVQ2/nOzhbbd8cdd2j48OFq06aNLl68qC+//FJxcXFKSEjQ5s2by531u5aU/aE3Xf8PCAhQaWmpUlNT1bZt27ouzWl06NBB48aNU/v27VVUVKQdO3ZoxYoV2rZtm7Zs2VKv7524UnFxsRYuXCg3N7cqL2NXdeyUjenQoYPtC3WAmuwb6fIHld95550KDw+Xq6ur9uzZo7i4OG3btk0bN25UeHh4HVRtXytWrNALL7xgaYeGhmrp0qXq2bNnpfOulWPnavePZJvjp0GEpOq+dbuiEFDb+c7OFtu3ZcsWq/ZDDz2k8PBwzZkzR2+99Zaef/552xVcz+Tl5UmScR/z1vfLrrzkOHLkSPXs2VNPPPGEXn31Vb3xxhsOqsz2XnzxRe3evVsvvfSS2rVrV+nYa+3Yqcm+kaTY2Fir9n333aehQ4cqMjJSM2fOtNxqUZ8NGzZM7du3V3Z2tg4dOqSNGzdW66nYa+XYudr9I9nm+GkQIcnb21tnz541LqvuW7trM9/Z2Wv7Jk2apAULFmjz5s3XdEgqe0Ln0qVL5Z7WaQjHj72MHj1ac+bM0ebNmx1dis3MnTtXcXFxio6O1pQpU6oc/9tj50oN7dip6b6pSM+ePdWzZ09t375deXl5VT4h5+yCgoIsr1KJjIzUvffeqwEDBig/P7/S/XStHDtXu38qUtPjp0Hck8Rbuytnr+1zd3e3rPta9ttT21dKSUmRi4uLWrVqVddl1QuhoaEN5vh59dVXFRMTo7Fjx+r111+v1pyqjp3fjqnPrmbfVCY0NFTFxcU1unm3vujYsaMiIiK0bNmySsddK8fOlaq7fypTk+OnQYQk3tpdOXttX35+vpKTk9WiRQtblFlvdenSRZL0/fffl1u2Z88etWvX7pq+Z6syx48fbxDHz/z587VgwQI9+OCDevPNN+Xi4lKteZUdO7t371bTpk3r/b1sV7tvKvPLL7/Izc2tXr8nqTJ5eXk6f/58pWOuhWOnItXZP5WpyfHTIEKSrd7aXZ359VFt98+5c+eM6503b56Kioo0ZMgQ2xftpJKSkpSYmGj1aO3vf/97eXl5KS4uTsXFxZb+jRs36vjx4/X++KkJ0/6p6JdZXFycTp8+Xe+PnwULFmj+/PkaM2aMYmNjK3wxa2pqqhITE63uE+nVq5datWqlFStWWD0BefjwYe3YsUP33Xef3N3d7b4N9lKbfXPhwgWr/5/KbNq0Sbt27VL//v3l6elpt9rtLS0tzdi/bds2HTlyRF27drX0XYvHTm33j62OH6d4maQt2Oqt3VXNr69qs3+mT5+uPXv2qE+fPgoODlZOTo42b96s7du3q2vXrlq3bl29vi/gww8/VFJSkiRp6dKlKigo0NNPPy3p8js5HnzwQcvYYcOGKSEhQQcPHlTr1q0t/W+++aZmzZql3r17a9SoUUpOTtbixYsVFBSkr776ql6fSart/omNjdX777+vu+++W6GhoZan2zZs2KA2bdroyy+/lL+/f91vmA3ExcVp6tSpCg4O1syZM8v9nmjRooX69+8vSZowYYLi4+O1bt069enTxzLms88+06OPPmp5a/LFixcVGxsrFxcXffPNNwoMDKzTbbKV2u6b9evXa+bMmRoyZIjCwsLk5uamvXv3atWqVWrWrJk2bdpUr8+UjB07Vmlpaerbt69CQkKUn5+vAwcO6NNPP5WXl5fWr1+viIgISdfesSPVfv/Y6vhpEDduS5dP6YaGhmr58uXavHmz/Pz8NH78eM2YMaNaAae2851dbbavd+/eOnr0qOLj43Xu3Dm5urrqxhtv1KxZs/SnP/2pXv9rTpJWrlyphIQEq7558+ZJuvyvtd+GgIpMnDhRN9xwg2JjYzVt2jQ1adJEw4cP11/+8pd6HZCk2u+fLl26aNu2bVq9erXS09NVWlqq1q1ba/LkyZo8ebJ8fX3tVru9lb2r5tdffy33slbp8v4pCwIVGT58uDw9PRUTE6NZs2bJw8ND/fr10+zZs+v1H7na7pt27drp9ttv16ZNm3T27FkVFhYqMDBQjz32mKZMmVKv940kjRo1SvHx8frXv/6l9PR0ubi4KCQkRNHR0Zo0aZLlpYmVaajHjlT7/WOr46fBnEkCAACwpfp/igQAAMAOCEkAAAAGhCQAAAADQhIAAIABIQkAAMCAkAQAAGBASAIAADAgJAEAABgQkgA0eCtWrNDkyZN19913KyAgQL6+vpo7d66jywLg5BrMx5IAQEX+/Oc/KysrS76+vmrVqpWOHz/u6JIA1AOcSQLQ4L377rs6dOiQTpw4oeeff97R5QCoJwhJAOqdP/7xj/L19dXbb79dbtncuXPl6+uriRMnWvoGDhyo0NDQuiwRQANASAJQ7yxevFjBwcF66aWXdPDgQUv/1q1b9dprr+mWW27RggULHFghgIaAkASg3mnWrJmWLVum4uJiPfbYY8rOztbZs2c1fvx4NW7cWO+99568vb0dXSaAeo6QBKBe+t3vfqeZM2fq559/1rPPPqvx48crLS1NCxYsUIcOHRxdHoAGgKfbANRbkydP1o4dO/TRRx9JkkaNGqVx48Y5uCoADQVnkgDUWy4uLoqMjLS0J0yY4MBqADQ0hCQA9dbPP/+sWbNmydfXV40aNdLEiROVn5/v6LIANBCEJAD10qVLl/Too48qJydH7777rqZMmaIff/xR06dPd3RpABoIQhKAeunPf/6zDh06pGeeeUYDBgzQ9OnTdeedd+q9997T6tWrHV0egAbAJTMzs9TRRQBATaxfv14PP/ywunbtqi+++EJubpefQfn111/Vp08fFRcXa9u2bQoLC5N0+bPbdu7cKUk6fvy4du3apfDwcEVEREiS2rdvr2effdYh2wLAeRGSANQrSUlJ6tOnj0pKSqyCUJkNGzZo7Nix6tKli7744gt5eHhowoQJio+Pr3CdvXr10oYNG+xcOYD6hpAEAABgwD1JAAAABoQkAAAAA0ISAACAASEJAADAgJAEAABgQEgCAAAwICQBAAAYEJIAAAAMCEkAAAAGhCQAAACD/w+8RAsNa3Bb7QAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 576x576 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Set random seed to ensure reproducible runs\n",
    "RSEED = 50\n",
    "\n",
    "X = np.array([[2, 2], \n",
    "              [2, 1],\n",
    "              [2, 3], \n",
    "              [1, 2], \n",
    "              [1, 1],\n",
    "              [3, 3]])\n",
    "\n",
    "y = np.array([0, 1, 1, 1, 0, 1])\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "\n",
    "# Plot formatting\n",
    "plt.style.use('fivethirtyeight')\n",
    "plt.rcParams['font.size'] = 18\n",
    "plt.figure(figsize = (8, 8))\n",
    "\n",
    "# Plot each point as the label\n",
    "for x1, x2, label in zip(X[:, 0], X[:, 1], y):\n",
    "    plt.text(x1, x2, str(label), fontsize = 40, color = 'g',\n",
    "             ha='center', va='center')\n",
    "    \n",
    "# Plot formatting\n",
    "plt.grid(None);\n",
    "plt.xlim((0, 3.5));\n",
    "plt.ylim((0, 3.5));\n",
    "plt.xlabel('x1', size = 20); plt.ylabel('x2', size = 20); plt.title('Data', size = 24)\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "# Make a decision tree and train\n",
    "tree = DecisionTreeClassifier(random_state=RSEED)\n",
    "tree.fit(X, y)\n",
    "\n",
    "\n",
    "print(f'Decision tree has {tree.tree_.node_count} nodes with maximum depth {tree.tree_.max_depth}.')\n",
    "print(f'Model Accuracy: {tree.score(X, y)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "在得到森林之后，当有**一个新的输入样本进入**的时候，就让森林中的**每一棵决策树分别进行一下判断**，看看这个样本应该属于哪一类（对于分类算法），然后**看看哪一类被选择最多**，就预测这个样本为那一类。\n",
    "\n",
    "随机森林可以既可以处理属性为离散值的量，比如ID3算法，也可以处理属性为连续值的量，比如C4.5算法。另外，随机森林还可以用来进行无监督学习聚类和异常点检测。\n",
    "\n",
    "随机森林实际上也属于“集成学习”的范畴。\n",
    "\n",
    "本节只讨论RF，其余的如Boosting和Bagging等\n",
    "\n",
    "### 算法内容\n",
    "\n",
    "RF的基本思（tao）想（lu）是通过“自助采样”的方法来增加多样性。它的基学习器固定为决策树，多棵树也就组成了森林，而“随机”则在于**选择划分属性的随机**，随机森林在训练基学习器时，也采用**有放回采样的方式添加样本扰动**，同时它还**引入了一种属性扰动**，即在基决策树的训练过程中，**在选择划分属性时，RF先从候选属性集中随机挑选出一个包含K个属性的子集，再从这个子集中选择最优划分属性**，一般推荐K=log2（d）。\n",
    "\n",
    "这样随机森林中基学习器的多样性不仅来自样本扰动，还来自属性扰动，从而进一步提升了基学习器之间的差异度。随机森林的**起始性能较差**（由于属性扰动，基决策树的准确度有所下降），但随着基学习器数目的增多，随机森林往往**会收敛到更低的泛化误差**。\n",
    "\n",
    "#### 随机采样\n",
    "\n",
    "随机森林的一大关键是每个树都在随机的数据点样本上进行训练。这些样本是可重复地抽取出来的（称为 bootstrapping），也就是说某些样本会多次用于单个树的训练（如果有需要，也可以禁止这种做法）。其思路是，**通过在不同样本上训练每个树，尽管每个树依据训练数据的某个特定子集而可能有较高方差，但整体而言整个森林的方差会很低**。这种在数据的不同子集上训练每个单个学习器然后再求预测结果的平均的流程被称为 bagging，这是 bootstrap aggregating 的缩写。\n",
    "\n",
    "#### 特征的随机子集\n",
    "\n",
    "随机森林背后的另一个概念是：**在每个决策树中，分割每个节点时都只会考虑所有特征中的一个子集**。通常设定为 sqrt(n_features)，意思是在每个节点，决策树会基于一部分特征来考虑分割，这部分特征的数量为总特征数量的平方根。随机森林也可以在每个节点考虑所有特征来进行训练。（在 Scikit-Learn 随机森林实现中，这些选项是可调控的。）\n",
    "\n",
    "如果你理解了单个决策树、bagging 决策树、特征的随机子集，那你就可以很好地理解随机森林的工作方式了。随机森林组合了数百或数千个决策树，并会在稍有不同的观察集上训练每个决策树（数据点是可重复地抽取出来的），并且会根据限定数量的特征分割每个树中的节点。随机森林的最终预测结果是每个单个树的预测结果的平均。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.3]\n",
      "[0.3 1.6]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\Programs\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    " \n",
    "data=[[0,0,0],[1,1,1],[2,2,2]]\n",
    " \n",
    "target=[0,1,2]\n",
    " \n",
    "rfr=RandomForestRegressor()\n",
    " \n",
    "rfr.fit(data,target)   #训练数据\n",
    " \n",
    "print(rfr.predict([[1,1,1]]))    #预测数据\n",
    "\n",
    "print(rfr.predict([[1,1,1],[2,2,2]]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 特征重要性\n",
    "\n",
    "现实情况下，一个数据集中往往有成百上前个特征，如何在其中选择比结果影响最大的那几个特征，以此来缩减建立模型时的特征数是我们比较关心的问题。这样的方法其实很多，比如主成分分析PCA（可见本文件夹下另一篇记录），lasso等等。不过，这里只简单介绍用随机森林来对进行特征筛选。\n",
    "\n",
    "feature importance,特征的重要性表示**特征对预测结果影响程度**，某一特征重要性越大，表明该特征对预测结果的影响越大，重要性越小，表明该特征对预测结果越小。RFR中某一特征的重要性，是**该特征在内部所有决策树重要性的平均值**，说白了就是看看每个特征在随机森林中的每颗树上做了多大的贡献，然后取个平均值，最后比一比特征之间的贡献大小。\n",
    "\n",
    "那么这个贡献是怎么一个说法呢？通常可以用基尼指数（Gini index）或者袋外数据（OOB）错误率作为评价指标来衡量。\n",
    "\n",
    "在决策树中，计算某一个特征的重要性有多种方法，sklearn内部采用的方法如下：\n",
    "\n",
    "某一节点 k 的重要性为\n",
    "$$n_k=\\omega_k*G_k-\\omega_{left}*G_{left}-\\omega_{right}*G_{right}$$\n",
    "\n",
    "其中，$\\omega_k,\\omega_{left},\\omega_{right}$分别为**节点k以及其左右子节点中训练样本个数与总训练样本数目的比例**， $G_k,G_{left},G_{right}$分为**节点 k以及其左右子节点的不纯度**。知道每一个节点的重要性之后，即可通过公式得出某一feature的重要性:\n",
    "$$f_i=\\frac{\\sum_{j\\in nodes\\ split\\ on\\ feature\\ i}n_j}{\\sum_{k\\in\\ all\\ nodes}n_k}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 178 entries, 0 to 177\n",
      "Data columns (total 14 columns):\n",
      "Class label                     178 non-null int64\n",
      "Alcohol                         178 non-null float64\n",
      "Malic acid                      178 non-null float64\n",
      "Ash                             178 non-null float64\n",
      "Alcalinity of ash               178 non-null float64\n",
      "Magnesium                       178 non-null int64\n",
      "Total phenols                   178 non-null float64\n",
      "Flavanoids                      178 non-null float64\n",
      "Nonflavanoid phenols            178 non-null float64\n",
      "Proanthocyanins                 178 non-null float64\n",
      "Color intensity                 178 non-null float64\n",
      "Hue                             178 non-null float64\n",
      "OD280/OD315 of diluted wines    178 non-null float64\n",
      "Proline                         178 non-null int64\n",
      "dtypes: float64(11), int64(3)\n",
      "memory usage: 19.6 KB\n",
      " 1) Color intensity                0.182483\n",
      " 2) Proline                        0.158610\n",
      " 3) Flavanoids                     0.150948\n",
      " 4) OD280/OD315 of diluted wines   0.131987\n",
      " 5) Alcohol                        0.106589\n",
      " 6) Hue                            0.078243\n",
      " 7) Total phenols                  0.060718\n",
      " 8) Alcalinity of ash              0.032033\n",
      " 9) Malic acid                     0.025400\n",
      "10) Proanthocyanins                0.022351\n",
      "11) Magnesium                      0.022078\n",
      "12) Nonflavanoid phenols           0.014645\n",
      "13) Ash                            0.013916\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "url = 'http://archive.ics.uci.edu/ml/machine-learning-databases/wine/wine.data'\n",
    "df = pd.read_csv(url, header = None)\n",
    "df.columns = ['Class label', 'Alcohol', 'Malic acid', 'Ash', \n",
    "              'Alcalinity of ash', 'Magnesium', 'Total phenols', \n",
    "              'Flavanoids', 'Nonflavanoid phenols', 'Proanthocyanins', \n",
    "              'Color intensity', 'Hue', 'OD280/OD315 of diluted wines', 'Proline']\n",
    "\n",
    "import numpy as np\n",
    "np.unique(df['Class label'])\n",
    "\n",
    "df.info()\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "x, y = df.iloc[:, 1:].values, df.iloc[:, 0].values\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size = 0.3, random_state = 0)\n",
    "feat_labels = df.columns[1:]\n",
    "forest = RandomForestClassifier(n_estimators=10000, random_state=0, n_jobs=-1)\n",
    "forest.fit(x_train, y_train)\n",
    "\n",
    "importances = forest.feature_importances_\n",
    "indices = np.argsort(importances)[::-1]\n",
    "for f in range(x_train.shape[1]):\n",
    "    print(\"%2d) %-*s %f\" % (f + 1, 30, feat_labels[indices[f]], importances[indices[f]]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
