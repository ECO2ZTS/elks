{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LDA 算法简介\n",
    "\n",
    "本文主要参考了：[Index of /~cyy/learning/tutorials](http://www.cmlab.csie.ntu.edu.tw/~cyy/learning/tutorials/)，[机器学习中的数学(4)-线性判别分析（LDA）, 主成分分析(PCA)](https://www.cnblogs.com/LeftNotEasy/archive/2011/01/08/lda-and-pca-machine-learning.html)，[线性判别分析（Linear Discriminant Analysis）（一）](https://www.cnblogs.com/jerrylead/archive/2011/04/21/2024384.html)，[线性判别分析(Linear Discriminant Analysis, LDA）算法分析](https://blog.csdn.net/warmyellow/article/details/5454943)\n",
    "\n",
    "分类算法中最简洁的线性分类器就是LDA（linear discriminant algorithm）了。LDA可以看作是简化版的SVM，另外，PCA是一个和LDA非常相关的算法，最终的表现很相似，都是解一个矩阵特征值的问题。\n",
    "\n",
    "LDA的原理是，将**带上标签**的数据（点），通过投影的方法，**投影到维度更低的空间中**，使得投影后的点，会**形成按类别区分，一簇一簇的情况**，相同类别的点，将会在投影后的空间中更接近。\n",
    "\n",
    "要说明白LDA，首先得弄明白线性分类器(Linear Classifier)：因为LDA是一种线性分类器。对于K-分类的一个分类问题，会有K个线性函数：\n",
    "$$y_k(x)=w_k^Tx+w_{k0}$$\n",
    "当满足条件：对于所有的j，都有Yk > Yj,的时候，我们就说x属于类别k。\n",
    "\n",
    "这实际上是一种投影，是将一个高维的点投影到一条高维的直线上，LDA最求的目标是，给出一个**标注了类别的数据集，投影到了一条直线之后，能够使得点尽量的按类别区分开**。 LDA分类的一个目标是使得不同类别之间的距离越远越好，同一类别之中的距离越近越好。\n",
    "\n",
    "假设用来区分二分类的直线（投影函数)为：\n",
    "$$y=w^Tx$$\n",
    "类别i的原始中心点为：\n",
    "$$m_i=\\frac{1}{n_i}\\sum _{x\\in D_i} x$$\n",
    "投影后的中心点为：\n",
    "$$\\widetilde m_i=w^Tm_i$$\n",
    "那么类别点之间的分散程度（方差）为：\n",
    "$$\\widetilde s_i=\\sum _ {y\\in Y_i}{(y-\\widetilde {m_i})^2}$$\n",
    "最后可以得到一个LDA投影到w后的损失函数：\n",
    "$$J(w)=\\frac{|{\\widetilde m_1 - \\widetilde m_2}|^2}{{\\widetilde s_1}^2+{\\widetilde s_2}^2}$$\n",
    "分子是两个类别各自的中心点之间的距离的平方，分母是每一个类别内的方差之和，现在最大化J(w)就可以求出最优的w了。\n",
    "\n",
    "现在看看一个图示的例子：\n",
    "\n",
    "![](201104212324555025.jpg)\n",
    "\n",
    "不同的直线投影后的J(w)必然是不同的。\n",
    "\n",
    "回到数学表达式，该式的求解需要做些转换：令\n",
    "\n",
    "$$S_i=\\sum_{x\\in D_i}{(x-m_i)(x-m_i)^T}$$\n",
    "\n",
    "上式意思是某一个分类的输入点集D_i里面的点到这个分类的中心点的距离。\n",
    "所以J(w)的分母中项可以转换为：\n",
    "$$\\widetilde s_i=\\sum _ {x\\in D_i}{(w^Tx-w^Tm_i)^2}=\\sum _{x\\in D_i}{w^T(x-m_i)(x-m_i)^Tw}=w^TS_iw$$\n",
    "因此分母整个就是：\n",
    "$$w^T(S_1+S_2)w=w^TS_ww$$\n",
    "同理，分子就是：\n",
    "$$w^T(m_1-m_2)(m_1-m_2)^Tw=w^TS_Bw$$\n",
    "损失函数就是：\n",
    "$$J(w)=\\frac{w^TS_Bw}{w^TS_ww}$$\n",
    "利用拉格朗日法求解可有：\n",
    "$$S_Bw=\\lambda S_ww$$\n",
    "对于高维问题，有：\n",
    "$$S_Bw_i=\\lambda S_ww_i$$\n",
    "即\n",
    "$${S_w}^{-1}S_Bw_i=\\lambda w_i$$\n",
    "这是一个求特征值的问题，求出${S_w}^{-1}S_Bw_i$的特征值，然后取前k个特征向量组成W矩阵即可；第i大的特征向量，就是对应的$w_i$。\n",
    "\n",
    "实际应用中就可以利用LDA根据样本点训练一个分类器。\n",
    "\n",
    "比如利用LDA进行一个分类的问题：假设一个产品有两个参数来衡量它是否合格。cls1_data为合格样本，cls2_data为不合格的样本."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[2.95, 6.63],\n",
       "       [2.53, 7.79],\n",
       "       [3.57, 5.65],\n",
       "       [3.16, 5.47]])"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "cls1_data =   np.array( [[2.9500  ,  6.6300],\n",
    "    [2.5300  ,   7.7900],\n",
    "    [3.5700 ,    5.6500],\n",
    "[3.1600 ,    5.4700]])\n",
    "cls1_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[2.58, 4.46],\n",
       "       [2.16, 6.22],\n",
       "       [3.27, 3.52]])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cls2_data = np.array(   [[2.5800  ,  4.4600],\n",
    "    [2.1600  ,  6.2200],\n",
    "    [3.2700  ,  3.5200]])\n",
    "cls2_data"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
